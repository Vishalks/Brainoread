{
  "name": "Brainoread",
  "tagline": "This source code is of a tool which is a standalone binary classifier using machine learning algorithms from R and Java. Currently used for diagnosis of patients suffering from brain disorders.",
  "body": "# Methods for increasing accuracy\r\nMost of the algorithms are used individually in the first iterations. The results generated from top models can be sorted according to prediction accuracy and then they can be combined further for increasing accuracy.\r\n\r\n##  k-fold Cross Validation \r\nCross Validation is the method where we divide the entire training data into parts. k is the parameter through which we decide how many such parts should be made. Of them, we use 1 part for testing and k – 1 parts for training. Such training – testing cycle is repeated until all parts are dropped for testing i.e. the loop runs k times. For a value of k = 10, we divide the dataset into 10 parts; train for 9 parts and test for 1 part. Such process is repeated until every single part is used for testing and remaining 9 for training. Thus, the loop iterates 10 times. \r\n\r\n## Stratified Sampling \r\nFor determining the best model we initially do stratified sampling of the training data. It is similar to k-fold cross validation. Here, we divide the entire data set into ratio of 70:30. We use the createDataPartition function of Caret package and pass parameter as 0.7. The training dataset is divided into random 70% and 30% of which we use 70% for training and 30% for testing. We repeat this procedure of randomly dividing the dataset into 70% and 30% for 100 iterations. The accuracy for each iteration is recorded and finally, average accuracy of prediction of data is calculated by taking the average of 100 accuracies. \r\n\r\n## Feature Selection \r\nFeature Selection includes selection of most important features from a list of all features. Feature Selection helps the model to solve the problem of overfitting the training set. That is, it reduces variance from the train set. The methods used for feature selection are:\r\n* Recursive Feature Elimination (RFE) \r\n* Simulated Annealing Feature Selection (SAFS) \r\n* varImp for Random Forest \r\n\r\n\r\n# Brainoread\r\nThis source code is a tool which is a standalone binary classifier using machine learning algorithms from R and Java. Currently used for diagnosis of patients suffering from brain disorders.\r\n\r\n## Visible methods\r\n### 1) getBestModel(x, y, iter = 100, verboseIter = FALSE){…}\r\n####file : getBestModel.r\r\n\r\nThis function takes features(x) and labes(y) of training dataset as input, performs data\r\npreprocessing (replace NA and NaN with 0). Evaluate train data for each model with\r\nstratified sampling (70% - 30%) “iter” times, which is 100 by default. Function\r\nreturns a dataframe with model-name, environment, averaged AUC, specificity,\r\nsensitivity, PPV, NPV. This function calls hidden methods getModelList() and\r\ngetAvgAUC() to get dataframe to be return with default 0 values and get averaged\r\nvalues for “iter” iteration for each model in dataframe.\r\n\r\n### 2) getTrainModel(x, y, methodName, verboseIter = FALSE, tuneLength = 10){…}\r\n#### file : trainPredict.r\r\n\r\nThis function takes same features(x), and labels(y) of training dataset as input with\r\nextra argument methodName – this is a row from dataframe returned by\r\ngetBestModel(). This function train model if the environment is R then tuneLength\r\nparameter is used. For R environment trainControl() and train() from caret are used,\r\nand if environment is JAVA then train dataset (features and labels) is written in file\r\nand calls the hidden method javaCall(), this function calls java methods using rJava\r\nlibrary. Final model is written in file (currentModel.rds for R and currentModel.obj\r\nfor java). This function returns vector with model-name and environment.\r\n\r\n### 3) getPredictProb(model, testData){…}\r\n#### file : trainPredict.r\r\n\r\nThis function uses model (vector return from getTrainModel) and test dataset as\r\ninput. If environment is R model written in currentModel.rds is read and predict()\r\nmethod from caret is used to get prediction probabilities, and for JAVA environment\r\ntest dataset is written in file with extra result file and call is made to javaCall()\r\nmethod, to get prediction probabilities java class writes result in result_prob.csv file\r\nwhich is read by hidden method getPredFromFile(). Function returns dataframe with\r\nboth class probabilities.\r\n\r\n### 4) getLastModel(){…}\r\n#### file : trainPredict.r\r\nMethod getTrainModel() creates one additional file info.csv which contains labels of\r\nclass, model-name and environment information. This function reads that file and\r\nreturns a vector same as getTrainModel() returns.\r\n\r\n## Hidden Methods\r\n\r\n### 1) getModelList(){…}\r\n#### file : getAUC.r\r\nThis function creates a dataframe of model-name, environment and accuracy value fields\r\nwith default 0 and returns that dataframe.\r\n\r\n### 2) getAvgAUC(x, y, methodName, iter, verboseIter){…}\r\n#### file : getAUC.r\r\nThis method takes features(x), labels(y), method-name (row of model-list) and number of\r\niterations to be performed. Function returns vector with averaged values of accuracy\r\nvalues. This function perform stratified sampling (70% - 30%) 70% is used for training\r\nand 30% is used for testing. If environment is R then train() and predict() from caret is\r\nused. If environment is JAVA then train and test dataset is written in files with addition\r\nresult file, and a call is made to javaCall() method. Java writes result in file which is read\r\nby getPredFromFile() method. AUC is caluculated using caTools::colAUC() method and\r\nrest values are calculated using caret::confusionMatrix() method.\r\n\r\n### 3) removeNaN(x){…}\r\n#### file : getAUC.r\r\nThis file replaces NaN values with 0 from dataframe and returns that dataframe .\r\n\r\n### 4) getPredFromFile(){…}\r\n#### file : getAUC.r\r\nJava writes predictions of positive class in result_prob.csv. This functions reads this file\r\nand place probabilities of negative class and returns dataframe with both class\r\nprobabilities.\r\n\r\n### 5) javaCall (modelName, train = FALSE, test = FALSE){…}\r\n#### file :javaCall.R\r\nThis function uses rJava to create object of java class file and calls method of that class\r\ninstance. This method uses model-name, with train and test arguments. If train and test\r\nboth are false then java methods performs both training and testing (used for stratified\r\nsampling). If train is true then only train model and save in model in file, and if test is\r\ntrue then read model saved in file test the dataset and write prediction in result_prob.csv\r\n\r\n*Demo script is written in test.r file with dementia dataset (demen.csv)*\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}