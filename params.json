{
  "name": "Brainoread",
  "tagline": "This source code is of a tool which is a standalone binary classifier using machine learning algorithms from R and Java. Currently used for diagnosis of patients suffering from brain disorders.",
  "body": "# About\r\nWe have created a generic binary classiﬁer which we currently use for diagnosis of patients suﬀering from brain disorders. However, the tool is powerful enough to work on any binary class classiﬁcation problem. On prediction of 119,748 test subjects for Schizophrenia, we got a maximum accuracy of **91.78%**. And on cross validation of Dementia dataset, we got the maximum accuracy of close to **100%**. \r\nThis tool can be easily ported to hospitals and can be used for prediction of any data provided the model is initially trained using similar known dataset. Initially the tool takes time for training all models and then tunes those using diﬀerent tuning parameters, and once the model is trained; prediction can be done in very less time. It provides the advantage of saving the model so it can be reused any number of times. \r\nMoreover, the prediction accuracy of the model can be increased by manually adding training subjects to the dataset.\r\n\r\n# Features extracted from MRI scans\r\n## FNC Features\r\nFunctional Network Connectivity (FNC) are relationship values that compress the general association between free cerebrum maps after some time.Therefore, the FNC feature gives a picture of the availability design after sometime between autonomous systems (or brain maps). These FNC features were obtained by Group Independent Component Analysis (GICA) of MRI images. The MRI chosen for the task were of both, healthy people and people suﬀering from Schizophrenia. An arrangement of cerebrum maps and timecourses relating to these mind maps were achieved by the GICA disintegration of the fMRI information. These timecourses demonstrated the action level of the comparing cerebrum map at every point in time. The FNC features are the relationships between these timecourses. For interpretation, FNC demonstrates a subject’s general level of ”synchronicity” between mind areas.As this information is derived from functional MRI scans, FNCs are considered a functional modality feature. They describe patterns of the brain function.\r\n\r\n![](https://cloud.githubusercontent.com/assets/10834446/19800028/6355c83c-9d17-11e6-82b7-cf34fbda4eba.png)\r\n## SBM Features\r\nSource-Based Morphometry (SBM) loadings relate to the weights of brain maps obtained by applying Independent Component Analysis (ICA) on the gray-matter concentration maps.Gray-matter is the outer layer of the brain. Most of the signal processing of the brain occurs in gray-matter region.For interpretation, gray-matter concentrationindictes the ”computational power” available in a certain region of the brain.ICA investigation of basic MRI for gray-matter focus gives autonomous mind maps whose expres sion levels ﬂuctuate as indicated by the subjects. Basically, a close to zero stacking for a given ICA-determined mind map demonstrates that the cerebrum locales delineated in that guide are modest present in the subject (i.e., the presence of gray-matter concentration areas in those regions are very low in that subject). As this information is derived from structural MRI scans, SBM loadings are considered a structural modality feature. They describe patterns of the brain structure.\r\n\r\n![](https://cloud.githubusercontent.com/assets/10834446/19799291/8abb8aa0-9d13-11e6-839e-93dcbd1365a7.png)\r\n# Uses State of the Art Machine Learning Techniques\r\nMost of the algorithms are used individually in the first iterations. The results generated from top models can be sorted according to prediction accuracy and then they can be combined further for increasing accuracy. \r\n\r\n## k-fold Cross Validation \r\nCross Validation is the method where we divide the entire training data into parts. k is the parameter through which we decide how many such parts should be made. Of them, we use 1 part for testing and k – 1 parts for training. Such training – testing cycle is repeated until all parts are dropped for testing i.e. the loop runs k times. For a value of k = 10, we divide the dataset into 10 parts; train for 9 parts and test for 1 part. Such process is repeated until every single part is used for testing and remaining 9 for training. Thus, the loop iterates 10 times. \r\n\r\n## Stratified Sampling \r\nFor determining the best model we initially do stratified sampling of the training data. It is similar to k-fold cross validation. Here, we divide the entire data set into ratio of 70:30. We use the createDataPartition function of Caret package and pass parameter as 0.7. The training dataset is divided into random 70% and 30% of which we use 70% for training and 30% for testing. We repeat this procedure of randomly dividing the dataset into 70% and 30% for 100 iterations. The accuracy for each iteration is recorded and finally, average accuracy of prediction of data is calculated by taking the average of 100 accuracies. \r\n\r\n## Feature Selection\r\nFeature Selection includes selection of most important features from a list of all features. Feature Selection helps the model to solve the problem of overfitting the training set. That is, it reduces variance from the train set. The methods used for feature selection are: \r\n* Recursive Feature Elimination (RFE) \r\n* Simulated Annealing Feature Selection (SAFS)\r\n* varImp for Random Forest \r\n\r\n### FNC Feature Selection\r\n![](https://cloud.githubusercontent.com/assets/10834446/19798727/79ebf960-9d10-11e6-8dc0-eac3f261e8d8.png)\r\n### SBM Feature Selection\r\n![](https://cloud.githubusercontent.com/assets/10834446/19798729/7a2bf1b4-9d10-11e6-8aeb-3689df07ad21.png)\r\n\r\n# List of Algorithms \r\nOur package uses a list of all classification algorithms available in the mentioned packages. A few of the algorithms used for the project from Caret package are as follows:\r\n* gpls (Generic Partial Least Squares)\r\n* svm (Support Vector Machines)\r\n* nb (Naive Bayes)\r\n* nnet (Neural Network)\r\n* lda (Linear Discriminant Analysis)\r\n* rf (Random Forest)\r\n* wsrf (Weighted Subspace Random Forest)\r\n* LMT (Logistic Model Trees)\r\n* glm (Generalized Linear Model)\r\n* gbm (Gradient Boosting Machines)\r\n\r\n# System Design\r\nThe following is a flow chart that explains the work flow of the model.\r\n\r\n![](https://cloud.githubusercontent.com/assets/10834446/19798733/7a766ea6-9d10-11e6-8338-e65616915420.jpg)\r\n\r\n# Results and Analysis\r\n## Plot for Analysis of Dementia Patients \r\nBelow figure depicts the classification of Dementia patients plot against two features namely AWF and nWBV. We used a visualization function to give a graphical output of the data. The plot in red is people not suffering from Dementia whereas the blue plot shows the people suffering from the disease.\r\n\r\n![](https://cloud.githubusercontent.com/assets/10834446/19800029/6359ef2a-9d17-11e6-82a5-fdf744e89a57.png)\r\n\r\n# Visible methods\r\n### 1) getBestModel(x, y, iter = 100, verboseIter = FALSE){…}\r\n#### file : getBestModel.r\r\n\r\nThis function takes features(x) and labes(y) of training dataset as input, performs data\r\npreprocessing (replace NA and NaN with 0). Evaluate train data for each model with\r\nstratified sampling (70% - 30%) “iter” times, which is 100 by default. Function\r\nreturns a dataframe with model-name, environment, averaged AUC, specificity,\r\nsensitivity, PPV, NPV. This function calls hidden methods getModelList() and\r\ngetAvgAUC() to get dataframe to be return with default 0 values and get averaged\r\nvalues for “iter” iteration for each model in dataframe.\r\n\r\n### 2) getTrainModel(x, y, methodName, verboseIter = FALSE, tuneLength = 10){…}\r\n#### file : trainPredict.r\r\n\r\nThis function takes same features(x), and labels(y) of training dataset as input with\r\nextra argument methodName – this is a row from dataframe returned by\r\ngetBestModel(). This function train model if the environment is R then tuneLength\r\nparameter is used. For R environment trainControl() and train() from caret are used,\r\nand if environment is JAVA then train dataset (features and labels) is written in file\r\nand calls the hidden method javaCall(), this function calls java methods using rJava\r\nlibrary. Final model is written in file (currentModel.rds for R and currentModel.obj\r\nfor java). This function returns vector with model-name and environment.\r\n\r\n### 3) getPredictProb(model, testData){…}\r\n#### file : trainPredict.r\r\n\r\nThis function uses model (vector return from getTrainModel) and test dataset as\r\ninput. If environment is R model written in currentModel.rds is read and predict()\r\nmethod from caret is used to get prediction probabilities, and for JAVA environment\r\ntest dataset is written in file with extra result file and call is made to javaCall()\r\nmethod, to get prediction probabilities java class writes result in result_prob.csv file\r\nwhich is read by hidden method getPredFromFile(). Function returns dataframe with\r\nboth class probabilities.\r\n\r\n### 4) getLastModel(){…}\r\n#### file : trainPredict.r\r\nMethod getTrainModel() creates one additional file info.csv which contains labels of\r\nclass, model-name and environment information. This function reads that file and\r\nreturns a vector same as getTrainModel() returns.\r\n\r\n# Hidden Methods\r\n\r\n### 1) getModelList(){…}\r\n#### file : getAUC.r\r\nThis function creates a dataframe of model-name, environment and accuracy value fields\r\nwith default 0 and returns that dataframe.\r\n\r\n### 2) getAvgAUC(x, y, methodName, iter, verboseIter){…}\r\n#### file : getAUC.r\r\nThis method takes features(x), labels(y), method-name (row of model-list) and number of\r\niterations to be performed. Function returns vector with averaged values of accuracy\r\nvalues. This function perform stratified sampling (70% - 30%) 70% is used for training\r\nand 30% is used for testing. If environment is R then train() and predict() from caret is\r\nused. If environment is JAVA then train and test dataset is written in files with addition\r\nresult file, and a call is made to javaCall() method. Java writes result in file which is read\r\nby getPredFromFile() method. AUC is caluculated using caTools::colAUC() method and\r\nrest values are calculated using caret::confusionMatrix() method.\r\n\r\n### 3) removeNaN(x){…}\r\n#### file : getAUC.r\r\nThis file replaces NaN values with 0 from dataframe and returns that dataframe .\r\n\r\n### 4) getPredFromFile(){…}\r\n#### file : getAUC.r\r\nJava writes predictions of positive class in result_prob.csv. This functions reads this file\r\nand place probabilities of negative class and returns dataframe with both class\r\nprobabilities.\r\n\r\n### 5) javaCall (modelName, train = FALSE, test = FALSE){…}\r\n#### file :javaCall.R\r\nThis function uses rJava to create object of java class file and calls method of that class\r\ninstance. This method uses model-name, with train and test arguments. If train and test\r\nboth are false then java methods performs both training and testing (used for stratified\r\nsampling). If train is true then only train model and save in model in file, and if test is\r\ntrue then read model saved in file test the dataset and write prediction in result_prob.csv\r\n\r\n*Demo script is written in test.r file with dementia dataset (demen.csv)*\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}